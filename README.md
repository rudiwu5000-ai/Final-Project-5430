
# **README.md**

# WSB Sentiment Trading Simulation ‚Äì Repository Guide

This repository contains all scripts and datasets used to scrape WallStreetBets posts, extract stock price data, apply sentiment labels, and run a trading simulation based on positive sentiment signals.

## Files and What their purpose

### 1. subreddit_scrape.py

Scrapes recent WallStreetBets posts from Reddit.
Outputs:
Stock wallstreetbets.csv ‚Üí raw November WSB posts.

### 2. stockprice_scrape.py

Downloads stock price data for November for all tickers mentioned in WSB posts.
Outputs:
november_stock_data.csv

### 3. Stock wallstreetbets.csv

Raw scraped WSB posts from November.
Used for:

* Cleaning timestamps
* Matching stock mentions
* Applying sentiment model

### 4. `Stock_wallstreetbets_clean_timestamp.csv

A cleaned version of the raw WSB scrape, with:

* Standardized timestamps
* Extracted tickers
* Removed duplicates/irrelevant posts

Used as input for the sentiment labeling step.

### 5. wsb3000.py

Scrapes the top 3000 historical WSB posts.
This dataset is manually labeled by you to train a sentiment framework.

Outputs (not included):
wsb3000.csv (raw scraped top 3000 posts)

### 6.wsb3000_with_sentiment.csv

Manually labeled sentiment dataset.
Reference used for supervised sentiment modeling.

### 7. sentiment_apply.py

Applies the sentiment framework (from the labeled 3000 posts) to the cleaned November dataset.

Outputs:
Stock_wallstreetbets_with_ml_sentiment.csv

The November WSB posts now contain ML-based sentiment predictions.

### 8. project.Rmd

The main simulation and analysis file.

This script:

* Loads the ML-labeled WSB data
* Matches sentiment timestamps to stock price data
* Simulates $100 long positions for positive sentiment
* Applies 7% stop-loss and 25% take-profit rules
* Computes PnL, win rate, return distribution, exit reasons
* Generates visualizations
* Produces summary statistics and outputs for interpretation

This is the final step in the full workflow.

## Workflow Summary and pipeline

1. Scrape posts ‚Üí subreddit_scrape.py ‚Üí Stock wallstreetbets.csv
2. Clean timestamps & extract tickers** ‚Üí output: cleaned CSV
3. Scrape stock prices** ‚Üí stockprice_scrape.py ‚Üí november_stock_data.csv
4. Create sentiment model

   Scrape top posts ‚Üí wsb3000.py
   Manually label ‚Üí wsb3000_with_sentiment.csv
5. Apply sentiment to November posts ‚Üí sentiment_apply.py
6. Run trading simulation & analysis ‚Üí project.Rmd


## üìå **How to Explore the Repository**

If you want to understand the pipeline:

### Start Here

‚û°Ô∏è **`Stock wallstreetbets.csv`**
Raw WSB posts from November.

### Then Look at

‚û°Ô∏è **`Stock_wallstreetbets_clean_timestamp.csv`**
Cleaned version used for sentiment modeling.

### Check the Sentiment Framework

‚û°Ô∏è **`wsb3000_with_sentiment.csv`**
Your labeled training set.

### See ML Sentiment Applied

‚û°Ô∏è **`Stock_wallstreetbets_with_ml_sentiment.csv`**

### See Price Data

‚û°Ô∏è **`november_stock_data.csv`**

### Final Simulation

‚û°Ô∏è **`project.Rmd`**
This is where the trading logic and analysis are executed.

---

## üõ† Requirements

### Python (for scraping + sentiment)

Libraries used may include:

* `praw`, `requests`, `pandas`, `beautifulsoup4`, etc.

### R (for simulation)

Required packages:

* `tidyverse`
* `lubridate`
* `ggplot2`
* `scales`

